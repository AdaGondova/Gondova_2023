{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDATED_IGNORE=1\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.svm import NuSVR, NuSVC\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import LeaveOneOut, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pingouin as pg\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import random\n",
    "import pwlf\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score, mean_absolute_error, recall_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook used to set up the predictive pipeline\n",
    "Training is then shifted to a .py script because it takes a while! \n",
    "\n",
    "## GLOBAL INFO set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"../../DerivedData/cohorts_subjects_list.pickle\", \"rb\") as input_file:\n",
    "        cohorts = pickle.load(input_file)\n",
    "        \n",
    "# in the end outcomes are the scores, however here I am setting up the baselines predicting prematurity status etc\n",
    "outcomes = ['Cognitive Score','Language Score','Motor Score']\n",
    "n_folds = 46 # to recreate train/test proportions \n",
    "it_num = 1000 # for null distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READ IN DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ages\n",
    "df = pd.read_csv('../../DerivedData/cohortA_subjects_clinical.csv', index_col=0)\n",
    "\n",
    "### global FA\n",
    "glob = pd.read_csv('../../DerivedData/extracted_metrics/global_cortical_diffusion_metrics_median.csv', index_col=0)\n",
    "\n",
    "metrics = ['FA', 'L1', 'RD', 'MD']\n",
    "hemispheres = ['left', 'right']\n",
    "for metric in metrics:\n",
    "    for i, row in glob.iterrows():\n",
    "        glob.loc[i,metric] = np.mean([row['left_{}'.format(metric)], \n",
    "                                   row['right_{}'.format(metric)]])\n",
    "df = pd.merge(df, glob[['subject_id', 'FA']], on=['subject_id'])  \n",
    "\n",
    "### median FA regions \n",
    "diff = pd.read_csv('../../DerivedData/extracted_metrics/neonat_segmentation_diffusion_metric_median.csv', index_col=0)\n",
    "\n",
    "FA_cols = [col for col in diff.columns if 'FA' in col]\n",
    "FA_cols.extend(['subject_id'])\n",
    "\n",
    "#new_df = df.copy()\n",
    "df = pd.merge(df, diff[FA_cols], on=['subject_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nparcels = 128\\npath_to_random = '/neurospin/grip/external_databases/dHCP_CR_JD_2018/Projects/eLife_replication/DerivedData/extracted_metrics/'\\nrandom_df = pd.read_csv(os.path.join(path_to_random, 'random_parcellation_{}_diffusion_metric_median.csv'.format(parcels)), index_col=0)\\nsub_df = df[df.subject_id.isin(cohorts['D'])].copy()\\nrandom_df = pd.merge(random_df, sub_df[['subject_id', 'group_cat']], on='subject_id', how='inner')\\ninputs_random = [col for col in random_df.columns if 'FA' in col]\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to read in random parcellations, example here: \n",
    "'''\n",
    "parcels = 128\n",
    "path_to_random = '/neurospin/grip/external_databases/dHCP_CR_JD_2018/Projects/eLife_replication/DerivedData/extracted_metrics/'\n",
    "random_df = pd.read_csv(os.path.join(path_to_random, 'random_parcellation_{}_diffusion_metric_median.csv'.format(parcels)), index_col=0)\n",
    "sub_df = df[df.subject_id.isin(cohorts['D'])].copy()\n",
    "random_df = pd.merge(random_df, sub_df[['subject_id', 'group_cat']], on='subject_id', how='inner')\n",
    "inputs_random = [col for col in random_df.columns if 'FA' in col]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREMATURITY status prediction = baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create categories for Prematurity prediction \n",
    "df['group'] = 'FT'\n",
    "df.loc[df['GA_birth'] < 37, 'group'] = 'PT'\n",
    "\n",
    "df['group_cat'] = 0\n",
    "df.loc[df['GA_birth'] < 37, 'group_cat'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posible inputs: \n",
    "- GA birth \n",
    "- PMA scan \n",
    "- FA \n",
    "- corrected FA \n",
    "- GA birth + PMA scan \n",
    "- GA birth + PMA scan + FA \n",
    "- GA birth + PMA scan + corrected FA\n",
    "- Median FA regions (52) \n",
    "- Median FA regions (52) (corrected)\n",
    "<br>.... same for random parcellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \n",
    "    'GA birth' : [['GA_birth'], [0]], # 0 do not correct age, 1 do correct\n",
    "    'PMA scan' : [['PMA_scan'], [0]],\n",
    "    'FA' : [['FA'], [0]],\n",
    "    'FA' : [['FA'], [1]],\n",
    "    'GA birth + PMA scan' : [['GA_birth', 'PMA_scan'], [0,0]],\n",
    "    'GA birth + PMA scan + FA' : [['GA_birth', 'PMA_scan', 'FA'], [0,0,0]],\n",
    "    'GA birth + PMA scan + FA' : [['GA_birth', 'PMA_scan', 'FA'], [0,0,1]],\n",
    "    'Segmentation (52)' : [ FA_cols[:-1], np.zeros_like( FA_cols[:-1])],\n",
    "    'Segmentation (52) corrected' : [ FA_cols[:-1], np.ones_like( FA_cols[:-1])],\n",
    "}\n",
    "\n",
    "inputs = [['GA_birth'], \n",
    "         ['PMA_scan'],\n",
    "         ['FA'],\n",
    "         ['FA_corr'],\n",
    "         ['GA_birth', 'PMA_scan'],\n",
    "         ['GA_birth', 'PMA_scan', 'FA'],\n",
    "         ['FA_corr','GA_birth', 'PMA_scan'],\n",
    "         FA_cols[:-1], \n",
    "         [col+'_corr' for col in FA_cols[:-1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \n",
    "    'GA birth' : [['GA_birth'], [0]], # 0 do not correct age, 1 do correct\n",
    "    'PMA scan' : [['PMA_scan'], [0]],\n",
    "    'FA' : [['FA'], [0]],\n",
    "    'FA corr' : [['FA'], [1]],\n",
    "    'GA birth + PMA scan' : [['GA_birth', 'PMA_scan'], [0,0]],\n",
    "    'GA birth + PMA scan + FA' : [['GA_birth', 'PMA_scan', 'FA'], [0,0,0]],\n",
    "    'GA birth + PMA scan + FA corrected' : [['GA_birth', 'PMA_scan', 'FA'], [0,0,1]],\n",
    "    'Segmentation (52)' : [ FA_cols[:-1], np.zeros_like( FA_cols[:-1], dtype=int)],\n",
    "    'Segmentation (52) corrected' : [ FA_cols[:-1], np.ones_like( FA_cols[:-1], dtype=int)],\n",
    "}\n",
    "\n",
    "inputs = {\n",
    "    \n",
    "    'GA birth + PMA scan + FA corrected' : [['GA_birth', 'PMA_scan', 'FA'], [0,0,1]],\n",
    "    'FA corr' : [['FA'], [1]],\n",
    "}\n",
    "\n",
    "\n",
    "outcome = 'group_cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs, AUC mean (std), ACC mean (std), Spec mean (std), Sens mean (std), Permuted AUC (p-val)\n",
      "Correcting inputs: ['FA']\n",
      "GA birth + PMA scan + FA corrected, 0.942(0.005),0.942(0.005),1.000(0.000),0.884(0.010),0.942(0.000)\n",
      "Correcting inputs: ['FA']\n",
      "FA corr, 0.500(0.000),0.500(0.000),1.000(0.000),0.000(0.000),0.500(1.000)\n"
     ]
    }
   ],
   "source": [
    "sub_df = df[df.subject_id.isin(cohorts['A'])].copy()\n",
    "## shuffle the data \n",
    "sub_df = sub_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print('Inputs, AUC mean (std), ACC mean (std), Spec mean (std), Sens mean (std), Permuted AUC (p-val)')\n",
    "\n",
    "for key in inputs.keys():\n",
    "    \n",
    "    in_cols, for_corr_index = get_columns_to_correct(inDict=inputs, key=key)\n",
    "    \n",
    "    ### get inputs\n",
    "    X = sub_df[in_cols].values\n",
    "    y = sub_df[outcome].values\n",
    "    PMA_scan = sub_df['PMA_scan'].values\n",
    "    \n",
    "    ### example Kfold\n",
    "    res = get_repeated_Kfold(X=X, y=y, PMA_scan=PMA_scan, \n",
    "                             corr_idx=for_corr_index, n_folds=n_folds, \n",
    "                             mode='cat', num_reps=10)\n",
    "    null = get_null_distribution(X=X, y=y, PMA_scan=PMA_scan, \n",
    "                             corr_idx=for_corr_index, n_folds=n_folds, \n",
    "                             mode='cat', it=100)\n",
    "    \n",
    "    \n",
    "    auc_p = np.sum(null['acc']>=res['acc'][0]) / len(null['acc'])\n",
    "\n",
    "    print('{}, {:.3f}({:.3f}),{:.3f}({:.3f}),{:.3f}({:.3f}),{:.3f}({:.3f}),{:.3f}({:.3f})'.format(\n",
    "                        key,\n",
    "                        np.mean(res['auc']), np.std(res['auc']),\n",
    "                        np.mean(res['acc']), np.std(res['acc']),\n",
    "                        np.mean(res['spec']), np.std(res['spec']),\n",
    "                        np.mean(res['sens']), np.std(res['sens']),\n",
    "                        res['auc'][0],auc_p\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_null_distribution(X, y, PMA_scan, corr_idx, n_folds, mode, it=1000):\n",
    "    #this is basically repeated K-fold where y is shuffled!\n",
    " \n",
    "    if mode == 'cat':\n",
    "        res = {'auc' : [], 'acc' : [], 'spec' : [], 'sens' : []}\n",
    "        for i in range(it):\n",
    "            y_shuff = np.random.permutation(y)\n",
    "            y_true, y_pred = run_Kfold(X=X, y=y_shuff, PMA_scan=PMA_scan, \n",
    "                               corr_idx=for_corr_index, n_folds=n_folds, mode='cat')\n",
    "            auc, acc, spec, sens = evaluate(y_true=y_true, y_pred=y_pred, mode='cat')\n",
    "            res['auc'].append(auc)\n",
    "            res['acc'].append(acc)\n",
    "            res['spec'].append(spec)\n",
    "            res['sens'].append(sens)\n",
    "            \n",
    "    elif mode == 'cont':\n",
    "        res = {'rho' : [], 'pval' : [], 'mae' : []}\n",
    "        for i in range(it):\n",
    "            y_shuff = np.random.permutation(y)\n",
    "            y_true, y_pred = run_Kfold(X=X, y=y_shuff, PMA_scan=PMA_scan, \n",
    "                               corr_idx=for_corr_index, n_folds=n_folds, mode='cont')\n",
    "            rho, pval, mae = evaluate(y_true=y_true, y_pred=y_pred, mode='cont')\n",
    "            res['rho'].append(rho)\n",
    "            res['pval'].append(pval)\n",
    "            res['mae'].append(mae)\n",
    "    return res\n",
    "    \n",
    "\n",
    "def get_repeated_Kfold(X, y, PMA_scan, corr_idx, n_folds, mode, num_reps=100):   \n",
    "    if mode == 'cat':\n",
    "        res = {'auc' : [], 'acc' : [], 'spec' : [], 'sens' : []}\n",
    "        for i in range(num_reps):\n",
    "            X,y,PMA_scan = unison_shuffled_copies(a=X, b=y, c=PMA_scan)\n",
    "            y_true, y_pred = run_Kfold(X=X, y=y, PMA_scan=PMA_scan, \n",
    "                               corr_idx=for_corr_index, n_folds=n_folds, mode='cat')\n",
    "            auc, acc, spec, sens = evaluate(y_true=y_true, y_pred=y_pred, mode='cat')\n",
    "            res['auc'].append(auc)\n",
    "            res['acc'].append(acc)\n",
    "            res['spec'].append(spec)\n",
    "            res['sens'].append(sens)\n",
    "            \n",
    "    elif mode == 'cont':\n",
    "        res = {'rho' : [], 'pval' : [], 'mae' : []}\n",
    "        for i in range(num_reps):\n",
    "            X,y,PMA_scan = unison_shuffled_copies(a=X, b=y, c=PMA_scan)\n",
    "            y_true, y_pred = run_Kfold(X=X, y=y, PMA_scan=PMA_scan, \n",
    "                               corr_idx=for_corr_index, n_folds=n_folds, mode='cont')\n",
    "            rho, pval, mae = evaluate(y_true=y_true, y_pred=y_pred, mode='cont')\n",
    "            res['rho'].append(rho)\n",
    "            res['pval'].append(pval)\n",
    "            res['mae'].append(mae)\n",
    "    return res\n",
    "    \n",
    "    \n",
    "def unison_shuffled_copies(a, b, c):\n",
    "    assert len(a) == len(b) == len(c)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p], c[p]\n",
    "        \n",
    "        \n",
    "def run_Kfold(X, y, PMA_scan, corr_idx, n_folds, mode):\n",
    "    \n",
    "    loo = KFold(n_splits=n_folds)\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for train_index, test_index in loo.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        PMA_train, PMA_test = PMA_scan[train_index], PMA_scan[test_index]\n",
    "        \n",
    "        ## process inputs \n",
    "        X_train, X_test = _pre_process(X_train=X_train, X_test=X_test, \n",
    "                                       PMA_train=PMA_train, PMA_test=PMA_test, \n",
    "                                       corr_idx=corr_idx, inflection=36)\n",
    "        \n",
    "        y_out = run_model(X_train=X_train, X_test=X_test, \n",
    "                           y_train=y_train, y_test=y_test, \n",
    "                           mode='cat')\n",
    "        for el in range(len(y_test)):\n",
    "                y_true.append(y_test[el])\n",
    "                y_pred.append(y_out[el]) \n",
    "    return y_true, y_pred\n",
    "        \n",
    "def evaluate(y_true, y_pred, mode):\n",
    "    \n",
    "    if mode == 'cat':\n",
    "        ## auc, balanced acc, specificity, sensitivity \n",
    "        return roc_auc_score(y_true, y_pred), balanced_accuracy_score(y_true, y_pred), recall_score(y_true, y_pred, pos_label=0),recall_score(y_true, y_pred, pos_label=1) \n",
    "    if mode == 'cont':\n",
    "        return pg.corr(y_true, y_pred)['r'][0], pg.corr(y_true, y_pred)['p-val'][0], mean_absolute_error(y_true, y_pred)\n",
    "        \n",
    "\n",
    "def run_model(X_train, X_test, y_train, y_test, mode): \n",
    "    ## mode is 'cat' or 'cont'\n",
    "    if mode == 'cat':\n",
    "        clf = SVC( C=9, kernel='linear')\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_out = clf.predict(X_test)\n",
    "        \n",
    "        y_out[y_out>0.5]=1\n",
    "        y_out[y_out<=0.5]=0\n",
    "    \n",
    "    if mode == 'cont':\n",
    "        clf = NuSVR(C=9, kernel='linear')\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_out = clf.predict(X_test)\n",
    "    \n",
    "    return y_out\n",
    "\n",
    "def _pre_process(X_train, X_test, PMA_train, PMA_test, corr_idx, inflection=36):\n",
    "    \n",
    "    # impute median\n",
    "    X_train, X_test = _impute_median(X_train=X_train, X_test=X_test)\n",
    "    # correct age\n",
    "    if len(corr_idx) > 0 :\n",
    "        X_train, X_test = _correct_age(X_train=X_train, X_test=X_test, \n",
    "                                      PMA_train=PMA_train, PMA_test=PMA_test, corr_idx=corr_idx, inflection=36)\n",
    "        \n",
    "    X_train, X_test = _scaling(X_train= X_train, X_test = X_test)\n",
    "    \n",
    "    return X_train, X_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns_to_correct(inDict, key):\n",
    "    in_cols, for_corr_index = inDict[key][0], np.argwhere(np.array(inDict[key][1]) == 1).ravel()\n",
    "    if len(for_corr_index) > 0:\n",
    "        print('Correcting inputs: {}'.format(np.array(in_cols)[for_corr_index]))   \n",
    "    return in_cols, for_corr_index\n",
    "\n",
    "def _impute_median(X_train, X_test):\n",
    "    \n",
    "    for col in range(len(X_train[0])):\n",
    "        \n",
    "        md = np.nanmedian(X_train[:,col])\n",
    "        \n",
    "        X_train[:,col][np.isnan(X_train[:,col])] = md\n",
    "        X_test[:,col][np.isnan(X_test[:,col])] = md\n",
    "    \n",
    "    return X_train, X_test\n",
    "\n",
    "def _scaling(X_train, X_test):\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    \n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test\n",
    "\n",
    "def _correct_age(X_train, X_test, PMA_train, PMA_test, corr_idx, inflection=36):\n",
    "    x0 = np.array([min(PMA_train), inflection, max(PMA_train)])\n",
    "    \n",
    "    for idx in corr_idx:\n",
    "        myPWLF = pwlf.PiecewiseLinFit(PMA_train, X_train[:,idx])\n",
    "        myPWLF.fit_with_breaks(x0)\n",
    "        \n",
    "        ## correct train \n",
    "        yHat_train = myPWLF.predict(PMA_train)\n",
    "        res_train = X_train[:,idx] - yHat_train\n",
    "        \n",
    "        ## correct test \n",
    "        yHat_test = myPWLF.predict(PMA_test)\n",
    "        res_test = X_test[:,idx] - yHat_test\n",
    "        \n",
    "        X_train[:,idx] = res_train\n",
    "        X_test[:,idx] = res_test\n",
    "    return X_train, X_test   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
